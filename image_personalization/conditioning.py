import re
from typing import List, Tuple


def extract_titles_from_his_interaction(his_interaction: str, max_titles: int = 10) -> List[str]:
    """
    Extract title list from his_interaction field, keeping only title text.
    his_interaction format: (user_id, hist_asin, hist_title, hist_rating); may be multiple records concatenated.
    """
    if not his_interaction:
        return []

    content = his_interaction.strip()
    titles: List[str] = []
    
    # Split multiple records by '),('
    if '),(' in content:
        records = content.split('),(')
        for i, record in enumerate(records):
            # Clean leading/trailing parentheses
            if i == 0:
                record = record.lstrip('(')
            if i == len(records) - 1:
                record = record.rstrip(')')
            
            title = _parse_single_record(record)
            if title and title not in titles:
                titles.append(title)
                
    else:
        # Single record case
        record = content.strip('()')
        title = _parse_single_record(record)
        if title:
            titles.append(title)
    
    return titles[:max_titles]


def _parse_single_record(record: str) -> str:
    """
    Parse single record: user_id,asin,title,rating
    Consider that title may contain commas
    """
    parts = record.split(',')
    if len(parts) < 4:
        return ""
    
    # Find rating from back to front (should be numeric)
    rating_idx = -1
    for i in range(len(parts) - 1, 1, -1):  # Start from last, but keep at least first two for user_id and asin
        try:
            float(parts[i].strip())
            rating_idx = i
            break
        except ValueError:
            continue
    
    if rating_idx > 2:  # Ensure there's a title part
        title_parts = parts[2:rating_idx]
        title = ','.join(title_parts).strip()
        return title
    
    return ""


def build_preference_text(titles: List[str], max_tokens: int = 256) -> str:
    """
    Concatenate title list into user preference text. Control length with rough truncation.
    """
    if not titles:
        return ""
    text = " \n".join(titles)
    # Simple length limit (character level)
    if len(text) > max_tokens * 4:
        text = text[: max_tokens * 4]
    return text


def fuse_instruction_and_preference(
    instruction: str,
    preference_text: str,
    adaptive_weight: float,
) -> str:
    """
    Text-level instruction and preference fusion fallback solution:
    Since the underlying layer gets token/embedding through text encoder, then performs vector-level fusion;
    This provides a simplified text concatenation method for scenarios without direct embedding manipulation.

    Note: For embedding-level fusion, should use encoder output vector addition at upper layer:
        fused = instr_emb + adaptive_weight * pref_emb
    This function is mainly used as fallback when encoder interface is not directly exposed.
    """
    instruction = instruction or ""
    preference_text = preference_text or ""
    if not instruction and not preference_text:
        return ""
    if not preference_text:
        return instruction
    if not instruction:
        return preference_text
    # Inject adaptive weight in prompt form
    return f"{instruction}\nUser preferences (weight={adaptive_weight:.3f}): {preference_text}"

def build_enhanced_prompt(
    instruction: str,
    title: str,
    historical_preference: str,
    adaptive_weight: float,
) -> str:
    """
    Build enhanced prompt text: prioritize instruction+title, consider adaptive_weight user preferences
    
    Args:
        instruction: Original recommendation instruction (e.g., "Help me recommend items in the Video_Games field")
        title: Current item title (dataset field)
        historical_preference: Historical preference text (extracted from his_interaction)
        adaptive_weight: Adaptive weight generated by collaborative filtering (0-1, higher means historical preference is more important)
        
    Returns:
        Fused complete prompt text
    """
    # Always prioritize instruction + title core semantics
    if title.strip():
        base_prompt = f"{instruction}, {title}"
    else:
        base_prompt = instruction
    
    # Decide historical preference influence based on adaptive_weight
    if historical_preference.strip() and adaptive_weight > 0.1:
        # Convert weight to semantic description
        if adaptive_weight >= 0.7:
            influence_level = "strongly influenced by"
        elif adaptive_weight >= 0.4:
            influence_level = "moderately influenced by"
        else:
            influence_level = "slightly influenced by"
            
        # Limit historical preference length to avoid overwhelming main content
        hist_short = historical_preference[:150] + "..." if len(historical_preference) > 150 else historical_preference
        base_prompt += f", {influence_level} user's gaming history: {hist_short}"
    
    return base_prompt


