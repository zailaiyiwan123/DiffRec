#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import math
import torch
import torch.nn as nn
from safetensors.torch import safe_open

# ğŸ”§ å¤šåº“å…¼å®¹æ€§è¡¥ä¸
def apply_compatibility_patches():
    """ä¸ºæ—§ç‰ˆæœ¬çš„ç›¸å…³åº“æ·»åŠ å…¼å®¹æ€§è¡¥ä¸"""
    
    # è¡¥ä¸ 1: HuggingFace Hub å…¼å®¹æ€§
    try:
        import huggingface_hub
        if not hasattr(huggingface_hub, 'split_torch_state_dict_into_shards'):
            def split_torch_state_dict_into_shards(state_dict, *args, **kwargs):
                if isinstance(state_dict, dict):
                    total_size = sum(
                        p.numel() * p.element_size() 
                        for p in state_dict.values() 
                        if hasattr(p, 'numel') and hasattr(p, 'element_size')
                    )
                else:
                    total_size = 0
                return [state_dict], {"total_size": total_size, "all_sizes": [total_size] if total_size > 0 else [0]}
            huggingface_hub.split_torch_state_dict_into_shards = split_torch_state_dict_into_shards
            print("âœ… [è¡¥ä¸] HuggingFace Hub è¡¥ä¸å·²åº”ç”¨")
    except Exception as e:
        print(f"âš ï¸ [è¡¥ä¸] HuggingFace Hub è¡¥ä¸å¤±è´¥: {e}")
    
    # è¡¥ä¸ 2: Diffusers å…¼å®¹æ€§
    try:
        import diffusers
        if not hasattr(diffusers, 'FlowMatchEulerDiscreteScheduler'):
            print("âš ï¸ [è¡¥ä¸] ç¼ºå°‘FlowMatchEulerDiscreteSchedulerï¼Œä½¿ç”¨æ›¿ä»£")
            if hasattr(diffusers, 'EulerDiscreteScheduler'):
                diffusers.FlowMatchEulerDiscreteScheduler = diffusers.EulerDiscreteScheduler
                print("âœ… [è¡¥ä¸] ä½¿ç”¨EulerDiscreteScheduleræ›¿ä»£")
        
        # QwenImageTransformer2DModel è¡¥ä¸
        if not hasattr(diffusers.models, 'QwenImageTransformer2DModel'):
            print("âš ï¸ [è¡¥ä¸] ç¼ºå°‘QwenImageTransformer2DModel")
            try:
                from diffusers.models.transformer_2d import Transformer2DModel
                diffusers.models.QwenImageTransformer2DModel = Transformer2DModel
                print("âœ… [è¡¥ä¸] ä½¿ç”¨Transformer2DModelæ›¿ä»£")
            except ImportError:
                # åˆ›å»ºåŸºç¡€æ›¿ä»£ç±»
                class BasicTransformer2D(nn.Module):
                    def __init__(self, in_channels=8, num_attention_heads=16, attention_head_dim=64, num_layers=1, cross_attention_dim=768, norm_num_groups=4, **kwargs):
                        super().__init__()
                        self.config = None
                        self.in_channels = in_channels
                        self.num_attention_heads = num_attention_heads
                        self.attention_head_dim = attention_head_dim
                        self.num_layers = num_layers
                        self.cross_attention_dim = cross_attention_dim
                    
                    @classmethod
                    def from_pretrained(cls, *args, **kwargs):
                        print("âš ï¸ [è¡¥ä¸] åˆ›å»ºåŸºç¡€Transformer2Dæ¨¡å‹")
                        return cls()
                    
                    def forward(self, x, *args, **kwargs):
                        return x
                
                diffusers.models.QwenImageTransformer2DModel = BasicTransformer2D
                print("âœ… [è¡¥ä¸] åˆ›å»ºåŸºç¡€Transformer2Dæ¨¡å‹")
    except Exception as e:
        print(f"âš ï¸ [è¡¥ä¸] Diffusers è¡¥ä¸å¤±è´¥: {e}")

# åº”ç”¨è¡¥ä¸
apply_compatibility_patches()

# ç°åœ¨å®‰å…¨å¯¼å…¥
try:
    from diffusers import DiffusionPipeline, FlowMatchEulerDiscreteScheduler
    from diffusers.models import QwenImageTransformer2DModel
    print("âœ… æˆåŠŸå¯¼å…¥diffusersç»„ä»¶")
except Exception as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")

def test_lora_loading():
    """æµ‹è¯•LoRAæƒé‡åŠ è½½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•LoRAæƒé‡åŠ è½½...")
    
    try:
        # 1. æ£€æŸ¥LoRAæ–‡ä»¶
        lora_path = "/root/autodl-tmp/Qwen-Image-Lightning/Qwen-Image-Lightning-4steps-V1.0.safetensors"
        if not os.path.exists(lora_path):
            print(f"âŒ LoRAæ–‡ä»¶ä¸å­˜åœ¨: {lora_path}")
            return False
        
        print(f"ğŸ“‚ æ‰¾åˆ°LoRAæ–‡ä»¶: {lora_path}")
        
        # 2. åŠ è½½LoRAæƒé‡
        lora_state_dict = {}
        with safe_open(lora_path, framework="pt", device="cpu") as f:
            for key in f.keys():
                lora_state_dict[key] = f.get_tensor(key)
        
        print(f"âœ… æˆåŠŸè¯»å– {len(lora_state_dict)} ä¸ªLoRAå‚æ•°")
        
        # 3. æ‰“å°ä¸€äº›æƒé‡ä¿¡æ¯
        print("ğŸ“Š LoRAæƒé‡ä¿¡æ¯:")
        for i, (key, tensor) in enumerate(lora_state_dict.items()):
            print(f"  {key}: {tensor.shape} ({tensor.dtype})")
            if i >= 5:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"  ... è¿˜æœ‰ {len(lora_state_dict) - 6} ä¸ªæƒé‡")
                break
        
        # 4. åˆ›å»ºåŸºç¡€æ¨¡å‹
        print("ğŸ”§ åˆ›å»ºåŸºç¡€transformeræ¨¡å‹...")
        # æä¾›å¿…è¦çš„å‚æ•°
        model = QwenImageTransformer2DModel(
            in_channels=8,  # å¿…é¡»å‚æ•°ï¼Œå¿…é¡»èƒ½è¢«norm_num_groups=8æ•´é™¤
            num_attention_heads=16,
            attention_head_dim=64,
            num_layers=1,
            cross_attention_dim=768,  # å¸¸ç”¨å€¼
            norm_num_groups=4  # æ˜ç¡®æŒ‡å®šnorm_num_groupsï¼Œç¡®ä¿èƒ½è¢«in_channelsæ•´é™¤
        )
        print("âœ… åŸºç¡€æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # 5. å°è¯•åˆå¹¶æƒé‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        print("ğŸ”€ å°è¯•åˆå¹¶LoRAæƒé‡...")
        merge_count = 0
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åŸç”Ÿæƒé‡æ ¼å¼
        is_native_weight = any("diffusion_model." in key for key in lora_state_dict)
        print(f"ğŸ“‹ æ£€æµ‹åˆ°{'åŸç”Ÿ' if is_native_weight else 'æ ‡å‡†'}æƒé‡æ ¼å¼")
        
        # ç®€å•è®¡æ•°æœ‰å¤šå°‘ä¸ªå¯åˆå¹¶çš„æƒé‡
        for key in lora_state_dict.keys():
            if ".lora_down.weight" in key:
                merge_count += 1
        
        print(f"âœ… å‘ç° {merge_count} ä¸ªå¯åˆå¹¶çš„LoRAæƒé‡å¯¹")
        
        return True
                        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_basic_pipeline():
    """æµ‹è¯•åŸºç¡€ç®¡é“åˆ›å»º"""
    print("ğŸ§ª æµ‹è¯•åŸºç¡€ç®¡é“åˆ›å»º...")
    
    try:
        # 1. åˆ›å»ºåŸºç¡€æ¨¡å‹
        model = QwenImageTransformer2DModel(
            in_channels=8,  # å¿…é¡»å‚æ•°ï¼Œå¿…é¡»èƒ½è¢«norm_num_groups=8æ•´é™¤
            num_attention_heads=16,
            attention_head_dim=64,
            num_layers=1,
            cross_attention_dim=768,  # å¸¸ç”¨å€¼
            norm_num_groups=4  # æ˜ç¡®æŒ‡å®šnorm_num_groupsï¼Œç¡®ä¿èƒ½è¢«in_channelsæ•´é™¤
        )
        print("âœ… åˆ›å»ºtransformeræ¨¡å‹")
        
        # 2. åˆ›å»ºè°ƒåº¦å™¨
        scheduler = FlowMatchEulerDiscreteScheduler()
        print("âœ… åˆ›å»ºè°ƒåº¦å™¨")
        
        # 3. åˆ›å»ºåŸºç¡€ç®¡é“
        pipe = DiffusionPipeline()
        print("âœ… åˆ›å»ºåŸºç¡€ç®¡é“")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ”¬ Qwen-Image-Lightning åŸºç¡€æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•1: LoRAæƒé‡åŠ è½½
    lora_success = test_lora_loading()
    
    # æµ‹è¯•2: åŸºç¡€ç®¡é“
    pipeline_success = test_basic_pipeline()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"  LoRAæƒé‡åŠ è½½: {'âœ… é€šè¿‡' if lora_success else 'âŒ å¤±è´¥'}")
    print(f"  åŸºç¡€ç®¡é“åˆ›å»º: {'âœ… é€šè¿‡' if pipeline_success else 'âŒ å¤±è´¥'}")
    
    if lora_success and pipeline_success:
        print("ğŸ‰ æ‰€æœ‰åŸºç¡€æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
    print("=" * 60)