#!/usr/bin/env python3
"""
è¯Šæ–­Qwen-Image-Lightningæ¨¡å‹åŠ è½½é—®é¢˜
"""

import os
import torch
from pathlib import Path

def check_lora_files():
    """æ£€æŸ¥LoRAæ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print("ğŸ” æ£€æŸ¥LoRAæ–‡ä»¶...")
    
    # é»˜è®¤è·¯å¾„
    base_paths = [
        "/root/autodl-tmp/Qwen-Image-Lightning",
        "./Qwen-Image-Lightning",
        "../Qwen-Image-Lightning",
        os.path.expanduser("~/Qwen-Image-Lightning")
    ]
    
    lora_filename = "Qwen-Image-Lightning-4steps-V1.0.safetensors"
    
    for base_path in base_paths:
        lora_path = os.path.join(base_path, lora_filename)
        print(f"ğŸ“‚ æ£€æŸ¥: {lora_path}")
        
        if os.path.exists(lora_path):
            file_size = os.path.getsize(lora_path) / (1024 * 1024)  # MB
            print(f"âœ… æ‰¾åˆ°LoRAæ–‡ä»¶: {lora_path}")
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            return lora_path
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {lora_path}")
    
    print("\nâš ï¸ æ²¡æœ‰æ‰¾åˆ°LoRAæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š")
    print("1. ç¡®è®¤Qwen-Image-Lightningæ¨¡å‹å·²ä¸‹è½½")
    print("2. æ£€æŸ¥è·¯å¾„é…ç½®æ˜¯å¦æ­£ç¡®")
    print("3. ç¡®è®¤æ–‡ä»¶åæ˜¯å¦æ­£ç¡®")
    return None

def apply_compatibility_patches():
    """åº”ç”¨å’Œè®­ç»ƒæ—¶ç›¸åŒçš„å…¼å®¹æ€§è¡¥ä¸"""
    print("\nğŸ”§ åº”ç”¨å…¼å®¹æ€§è¡¥ä¸...")
    
    try:
        import huggingface_hub
        
        # è¡¥ä¸ split_torch_state_dict_into_shards å‡½æ•°
        if not hasattr(huggingface_hub, 'split_torch_state_dict_into_shards'):
            def split_torch_state_dict_into_shards(state_dict, *args, **kwargs):
                """å…¼å®¹æ€§å‡½æ•°ï¼šæ¨¡æ‹Ÿ split_torch_state_dict_into_shards"""
                if isinstance(state_dict, dict):
                    total_size = sum(
                        p.numel() * p.element_size() 
                        for p in state_dict.values() 
                        if hasattr(p, 'numel') and hasattr(p, 'element_size')
                    )
                else:
                    total_size = 0
                
                return [state_dict], {
                    "total_size": total_size,
                    "all_sizes": [total_size] if total_size > 0 else [0]
                }
            
            huggingface_hub.split_torch_state_dict_into_shards = split_torch_state_dict_into_shards
            print("âœ… HuggingFace Hub å…¼å®¹æ€§è¡¥ä¸å·²åº”ç”¨")
            
    except Exception as e:
        print(f"âš ï¸ HuggingFace Hub è¡¥ä¸å¤±è´¥: {e}")
    
    try:
        import diffusers
        # æ£€æŸ¥æ˜¯å¦æœ‰ FlowMatchEulerDiscreteScheduler
        if not hasattr(diffusers, 'FlowMatchEulerDiscreteScheduler'):
            if hasattr(diffusers, 'EulerDiscreteScheduler'):
                diffusers.FlowMatchEulerDiscreteScheduler = diffusers.EulerDiscreteScheduler
                print("âœ… ä½¿ç”¨EulerDiscreteScheduleræ›¿ä»£FlowMatchEulerDiscreteScheduler")
            else:
                class FlowMatchEulerDiscreteSchedulerCompat:
                    @classmethod
                    def from_config(cls, config):
                        return cls()
                    def __init__(self):
                        self.num_train_timesteps = 1000
                diffusers.FlowMatchEulerDiscreteScheduler = FlowMatchEulerDiscreteSchedulerCompat
                print("âœ… ä½¿ç”¨å…¼å®¹æ€§è°ƒåº¦å™¨æ›¿ä»£FlowMatchEulerDiscreteScheduler")
    except Exception as e:
        print(f"âš ï¸ Diffusers è¡¥ä¸å¤±è´¥: {e}")

def check_diffusers_import():
    """æ£€æŸ¥diffuserså¯¼å…¥"""
    print("\nğŸ” æ£€æŸ¥diffuserså¯¼å…¥...")
    
    # å…ˆåº”ç”¨è¡¥ä¸
    apply_compatibility_patches()
    
    try:
        from diffusers import DiffusionPipeline
        print("âœ… DiffusionPipeline å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ DiffusionPipeline å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from diffusers import FlowMatchEulerDiscreteScheduler
        print("âœ… FlowMatchEulerDiscreteScheduler å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ FlowMatchEulerDiscreteScheduler å¯¼å…¥å¤±è´¥: {e}")
        print("âš ï¸ è¿™å¯èƒ½å¯¼è‡´ä½¿ç”¨å…¼å®¹æ€§è°ƒåº¦å™¨")
    
    return True

def test_lora_loading(lora_path):
    """æµ‹è¯•LoRAæƒé‡åŠ è½½"""
    if not lora_path:
        return False
        
    print(f"\nğŸ” æµ‹è¯•LoRAæƒé‡åŠ è½½: {lora_path}")
    
    try:
        from safetensors.torch import safe_open
        
        lora_state_dict = {}
        with safe_open(lora_path, framework="pt", device="cpu") as f:
            keys = list(f.keys())
            print(f"ğŸ“Š LoRAæ–‡ä»¶åŒ…å« {len(keys)} ä¸ªæƒé‡")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªé”®
            print("ğŸ“‹ æƒé‡é”®åç¤ºä¾‹:")
            for i, key in enumerate(keys[:5]):
                tensor = f.get_tensor(key)
                print(f"  - {key}: {tensor.shape} ({tensor.dtype})")
            
            if len(keys) > 5:
                print(f"  - ... è¿˜æœ‰ {len(keys) - 5} ä¸ªæƒé‡")
        
        print("âœ… LoRAæƒé‡åŠ è½½æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ LoRAæƒé‡åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\nğŸ” æµ‹è¯•åŸºç¡€æ¨¡å‹åˆ›å»º...")
    
    try:
        # å°è¯•åˆ›å»ºåŸºç¡€Transformer2Dæ¨¡å‹
        import torch.nn as nn
        
        class TestTransformer2D(nn.Module):
            def __init__(self, in_channels=8, **kwargs):
                super().__init__()
                self.norm = nn.GroupNorm(num_groups=4, num_channels=in_channels)
                
        model = TestTransformer2D()
        print("âœ… åŸºç¡€æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False

def check_image_generation_config():
    """æ£€æŸ¥å›¾åƒç”Ÿæˆé…ç½®"""
    print("\nğŸ” æ£€æŸ¥å›¾åƒç”Ÿæˆé…ç½®...")
    
    try:
        from image_personalization.qwen_image_trainer import QwenImageConfig
        
        cfg = QwenImageConfig()
        print(f"ğŸ“‚ é…ç½®çš„base_model: {cfg.base_model}")
        print(f"ğŸ·ï¸ é…ç½®çš„lora_weight_name: {cfg.lora_weight_name}")
        print(f"ğŸ¯ æ¨ç†æ­¥æ•°: {cfg.num_inference_steps}")
        print(f"âš–ï¸ CFGç¼©æ”¾: {cfg.true_cfg_scale}")
        
        # æ£€æŸ¥å®Œæ•´è·¯å¾„
        full_path = os.path.join(cfg.base_model, cfg.lora_weight_name)
        print(f"ğŸ“ å®Œæ•´LoRAè·¯å¾„: {full_path}")
        
        if os.path.exists(full_path):
            print("âœ… é…ç½®è·¯å¾„æ­£ç¡®")
            return full_path
        else:
            print("âŒ é…ç½®è·¯å¾„ä¸å­˜åœ¨")
            return None
            
    except Exception as e:
        print(f"âŒ é…ç½®æ£€æŸ¥å¤±è´¥: {e}")
        return None

def test_actual_image_generation():
    """æµ‹è¯•å®é™…çš„å›¾åƒç”Ÿæˆæµç¨‹"""
    print("\nğŸ” æµ‹è¯•QwenImageTrainerå®é™…å›¾åƒç”Ÿæˆ...")
    
    try:
        # å¯¼å…¥QwenImageTrainer
        from image_personalization.qwen_image_trainer import QwenImageTrainer, QwenImageConfig
        
        # åˆ›å»ºé…ç½®
        cfg = QwenImageConfig()
        print("âœ… é…ç½®åˆ›å»ºæˆåŠŸ")
        
        # åˆå§‹åŒ–è®­ç»ƒå™¨
        trainer = QwenImageTrainer(cfg)
        print("âœ… QwenImageTraineråˆå§‹åŒ–æˆåŠŸ")
        
        # æ£€æŸ¥ç®¡é“ç±»å‹
        pipe_type = type(trainer.pipe).__name__
        print(f"ğŸ” ç®¡é“ç±»å‹: {pipe_type}")
        
        if "Mock" in pipe_type:
            print("âŒ æ£€æµ‹åˆ°MockDiffusionPipeline - è¿™å°±æ˜¯ç”Ÿæˆå™ªå£°å›¾ç‰‡çš„åŸå› ï¼")
            print("ğŸ” æŸ¥çœ‹åˆå§‹åŒ–è¿‡ç¨‹ä¸­çš„é”™è¯¯ä¿¡æ¯...")
            return False
        else:
            print("âœ… ä½¿ç”¨çœŸå®çš„æ‰©æ•£ç®¡é“")
        
        # æµ‹è¯•å›¾åƒç”Ÿæˆ
        print("ğŸ¨ æµ‹è¯•å›¾åƒç”Ÿæˆ...")
        test_prompt = "Generate an image primarily focused on: Help me recommend items in Video Games, Xbox Controller."
        
        images = trainer.generate_image(test_prompt)
        
        if images and len(images) > 0:
            image = images[0]
            print(f"âœ… ç”Ÿæˆå›¾åƒæˆåŠŸ: {image.size}, æ¨¡å¼: {image.mode}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å™ªå£°å›¾åƒ
            import numpy as np
            img_array = np.array(image)
            
            # è®¡ç®—å›¾åƒçš„æ ‡å‡†å·® - å™ªå£°å›¾åƒé€šå¸¸æœ‰å¾ˆé«˜çš„æ ‡å‡†å·®
            std_dev = np.std(img_array)
            mean_val = np.mean(img_array)
            
            print(f"ğŸ“Š å›¾åƒç»Ÿè®¡: å‡å€¼={mean_val:.2f}, æ ‡å‡†å·®={std_dev:.2f}")
            
            # å™ªå£°å›¾åƒé€šå¸¸æ ‡å‡†å·®å¾ˆé«˜ï¼ˆ>60ï¼‰ï¼Œå‡å€¼æ¥è¿‘128
            if std_dev > 60 and 100 < mean_val < 156:
                print("âŒ æ£€æµ‹åˆ°å™ªå£°å›¾åƒç‰¹å¾ï¼")
                return False
            else:
                print("âœ… å›¾åƒçœ‹èµ·æ¥ä¸åƒçº¯å™ªå£°")
                return True
        else:
            print("âŒ å›¾åƒç”Ÿæˆå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ QwenImageTraineræµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def suggest_solutions():
    """å»ºè®®è§£å†³æ–¹æ¡ˆ"""
    print("\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
    
    print("ğŸ”§ å¦‚æœç”Ÿæˆå™ªå£°å›¾åƒï¼Œå¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š")
    print("\n1. LoRAæƒé‡åˆå¹¶é—®é¢˜ï¼š")
    print("   - æ£€æŸ¥load_and_merge_lora_weight_from_safetensorså‡½æ•°æ˜¯å¦æ­£ç¡®æ‰§è¡Œ")
    print("   - ç¡®è®¤LoRAæƒé‡é”®åå’Œæ¨¡å‹å‚æ•°ååŒ¹é…")
    print("   - éªŒè¯æƒé‡åˆå¹¶æ—¶çš„è®¾å¤‡ä¸€è‡´æ€§")
    
    print("\n2. æ‰©æ•£æ¨¡å‹é…ç½®é—®é¢˜ï¼š")
    print("   - æ£€æŸ¥è°ƒåº¦å™¨é…ç½®æ˜¯å¦æ­£ç¡®")
    print("   - ç¡®è®¤æ¨ç†æ­¥æ•°(num_inference_steps=4)æ˜¯å¦åˆé€‚")
    print("   - éªŒè¯CFGç¼©æ”¾(true_cfg_scale=1.0)è®¾ç½®")
    
    print("\n3. æ¨¡å‹åˆå§‹åŒ–é—®é¢˜ï¼š")
    print("   - ç¡®ä¿QwenImageTransformer2DModelå‚æ•°æ­£ç¡®")
    print("   - æ£€æŸ¥in_channelså’Œnorm_num_groupsçš„å…¼å®¹æ€§")
    print("   - éªŒè¯æ¨¡å‹æ˜¯å¦fallbackåˆ°MockDiffusionPipeline")
    
    print("\n4. ç¯å¢ƒå’Œä¾èµ–é—®é¢˜ï¼š")
    print("   - æ›´æ–°diffusersç‰ˆæœ¬: pip install diffusers --upgrade")
    print("   - ç¡®ä¿torchç‰ˆæœ¬å…¼å®¹: pip install torch>=1.12.0")
    print("   - æ£€æŸ¥CUDAç‰ˆæœ¬å’ŒGPUå†…å­˜")
    
    print("\n5. ä¸‹è½½å®Œæ•´æ¨¡å‹ï¼ˆå¦‚æœç¼ºå¤±ï¼‰ï¼š")
    print("   git clone https://huggingface.co/Qwen/Qwen-Image-Lightning")
    print("   æˆ–è€…å•ç‹¬ä¸‹è½½LoRAï¼š")
    print("   wget https://huggingface.co/Qwen/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V1.0.safetensors")
    
    print("\n6. è°ƒè¯•æ­¥éª¤ï¼š")
    print("   - è¿è¡Œ: python diagnose_image_model.py")
    print("   - æ£€æŸ¥è®­ç»ƒæ—¥å¿—ä¸­çš„ç®¡é“åˆå§‹åŒ–ä¿¡æ¯")
    print("   - ç¡®è®¤æ˜¯å¦çœ‹åˆ°'ä½¿ç”¨å ä½åŠŸèƒ½ï¼Œå›¾åƒç”Ÿæˆè¢«ç¦ç”¨'çš„è­¦å‘Š")
    
    print("\nğŸš¨ å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦ï¼š")
    print("   - é™çº§åˆ°ç¨³å®šçš„diffusersç‰ˆæœ¬")
    print("   - ä½¿ç”¨æ ‡å‡†Stable Diffusionè€ŒéQwen-Image-Lightning")
    print("   - æ£€æŸ¥å…¶ä»–æˆåŠŸæ¡ˆä¾‹çš„ç¯å¢ƒé…ç½®")

def main():
    """ä¸»è¯Šæ–­æµç¨‹"""
    print("ğŸ©º å¼€å§‹è¯Šæ–­Qwen-Image-Lightningæ¨¡å‹åŠ è½½é—®é¢˜...\n")
    
    # 1. æ£€æŸ¥LoRAæ–‡ä»¶
    lora_path = check_lora_files()
    
    # 2. æ£€æŸ¥diffuserså¯¼å…¥
    diffusers_ok = check_diffusers_import()
    
    # 3. æ£€æŸ¥é…ç½®
    config_path = check_image_generation_config()
    
    # 4. æµ‹è¯•LoRAåŠ è½½ï¼ˆå¦‚æœæ–‡ä»¶å­˜åœ¨ï¼‰
    if lora_path:
        lora_loading_ok = test_lora_loading(lora_path)
    else:
        lora_loading_ok = False
    
    # 5. æµ‹è¯•æ¨¡å‹åˆ›å»º
    model_creation_ok = check_model_creation()
    
    # 6. æµ‹è¯•å®é™…å›¾åƒç”Ÿæˆï¼ˆå…³é”®æµ‹è¯•ï¼‰
    image_generation_ok = False
    if lora_path and diffusers_ok and config_path:
        image_generation_ok = test_actual_image_generation()
    else:
        print("\nâš ï¸ è·³è¿‡å›¾åƒç”Ÿæˆæµ‹è¯•ï¼Œå› ä¸ºå‰ç½®æ¡ä»¶ä¸æ»¡è¶³")
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š è¯Šæ–­ç»“æœæ€»ç»“:")
    print("="*60)
    print(f"âœ… LoRAæ–‡ä»¶å­˜åœ¨: {'æ˜¯' if lora_path else 'å¦'}")
    print(f"âœ… Diffuserså¯¼å…¥: {'æ­£å¸¸' if diffusers_ok else 'å¼‚å¸¸'}")
    print(f"âœ… é…ç½®è·¯å¾„: {'æ­£ç¡®' if config_path else 'é”™è¯¯'}")
    print(f"âœ… LoRAåŠ è½½: {'æˆåŠŸ' if lora_loading_ok else 'å¤±è´¥'}")
    print(f"âœ… æ¨¡å‹åˆ›å»º: {'æˆåŠŸ' if model_creation_ok else 'å¤±è´¥'}")
    print(f"âœ… å›¾åƒç”Ÿæˆ: {'æ­£å¸¸' if image_generation_ok else 'å¼‚å¸¸/å™ªå£°'}")
    
    if image_generation_ok:
        print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡ï¼å›¾åƒç”Ÿæˆåº”è¯¥èƒ½æ­£å¸¸å·¥ä½œã€‚")
        print("å¦‚æœè®­ç»ƒæ—¶ä»ç„¶ç”Ÿæˆå™ªå£°ï¼Œå¯èƒ½æ˜¯è®­ç»ƒæ•°æ®æˆ–å…¶ä»–é…ç½®é—®é¢˜ã€‚")
    elif all([lora_path, diffusers_ok, config_path, lora_loading_ok, model_creation_ok]):
        print("\nâŒ è™½ç„¶æ‰€æœ‰ç»„ä»¶éƒ½æ­£å¸¸ï¼Œä½†å›¾åƒç”Ÿæˆå¼‚å¸¸ï¼")
        print("è¿™è¯´æ˜LoRAæƒé‡æ²¡æœ‰æ­£ç¡®åˆå¹¶æˆ–æ‰©æ•£è¿‡ç¨‹æœ‰é—®é¢˜ã€‚")
        suggest_solutions()
    else:
        print("\nâš ï¸ å‘ç°åŸºç¡€é—®é¢˜ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹å»ºè®®è§£å†³ï¼š")
        suggest_solutions()

if __name__ == "__main__":
    main()
